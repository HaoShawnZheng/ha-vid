# Multi-Object Tracking
This repository contains scripts and models for the Multi-Object Tracking benchmark of HA-ViD.

We benchmark [SORT](https://github.com/abewley/sort) and [ByteTrack](https://github.com/ifzhang/ByteTrack) on HA-ViD.

We benchmark the algorithms on both recognition results from [Object Dtection](https://github.com/iai-hrc/ha-vid/tree/main/ObjectDetection) and the ground truth annotations. Please refer to the subfolders for the details.

## Citation
If you find our code useful, please cite our paper. 
```
@inproceedings{
  author    = {Hao Zheng and
               Regina Lee and
               Yuqian Lu},
  title     = {HA-ViD: Human Assembly Video Dataset for Comprehensive Assembly Knowledge Understanding},
  journal = {}
}
```

## Acknowledgement

We appreciate the collaborators/maintainers of the [SORT](https://github.com/abewley/sort) and [ByteTrack](https://github.com/ifzhang/ByteTrack) repositories.

## License
HA-ViD is licensed by us under the Creative Commons Attribution-NonCommerial 4.0 International License. The terms are :
* Attribution : You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.
* NonCommercial : You may not use the material for commercial purposes.