# Action Recognition
This repository contains scripts and models for the Action Recognition benchmark of HA-ViD.

We benchmark I3D, TimeSFormer, and MVITv2 using the toolbox [MMAction2](https://github.com/open-mmlab/mmaction2), ST-GCN using the toolbox [MMSkeleton](https://github.com/open-mmlab/mmskeleton), and [TSM](https://github.com/mit-han-lab/temporal-shift-module) on HA-ViD.

Please refer to the subfolders for the details.

## Citation
If you find our code useful, please cite our paper. 
```
@inproceedings{
  author    = {Hao Zheng and
               Regina Lee and
               Yuqian Lu},
  title     = {HA-ViD: Human Assembly Video Dataset for Comprehensive Assembly Knowledge Understanding},
  journal = {}
}
```

## Acknowledgement

We appreciate the collaborators/maintainers of the [MS-TCN](https://github.com/yabufarha/ms-tcn), [DTGRM](https://github.com/redwang/DTGRM), and [BCN](https://github.com/MCG-NJU/BCN) repositories.

## License
HA-ViD is licensed by us under the Creative Commons Attribution-NonCommerial 4.0 International License. The terms are :
* Attribution : You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.
* NonCommercial : You may not use the material for commercial purposes.